\documentclass[table]{beamer}
%\usepackage[table]{xcolor}
\usepackage{amsmath, amsfonts, epsfig, xspace}
\usepackage[utf8]{inputenc}
\usepackage{algorithm,algorithmic}
\usepackage[normal,tight,center]{subfigure}
\setlength{\subfigcapskip}{-.5em}
\usepackage{beamerthemesplit}
% \usetheme{lankton-keynote}
\setbeamertemplate{headline}{} %Hide section stuff
\usepackage{natbib} %schönere Zitate
\usepackage{color}
\usepackage{fixltx2e}
\usepackage{pbox}

\definecolor{OliveGreen}{RGB}{0,155,85}

\author{Jonathan Oberländer}

\title[Automatic Detection of LQ Violations\hspace{8em}\insertframenumber]{Automatic Detection of Linguistic Quality Violations} %\insertframenumber/\inserttotalframenumber

\date{}

\institute{Bachelor Thesis Defense\\Universität des Saarlandes\\21.08.2014}

\begin{document}

\maketitle

\begin{frame}
  \frametitle{Automatic Summarization}
  \quad \quad \includegraphics[scale=0.1]{pics/documents.png} \includegraphics[scale=1]{pics/arrowlr.png} \includegraphics[scale=0.1]{pics/document.png}
\end{frame}

\begin{frame}
  \frametitle{Automatic Summarization}
  %types
  \begin{itemize}
    \item \textbf{Single-Document:} One document
    \item \textbf{Multi-Document:} Multiple documents on the same topic
  \end{itemize}
  \pause
  \begin{itemize}
    \item \textbf{Abstractive:} Internal semantic representation + generation
    \item \textbf{Extractive:} New summary from source sentences
  \end{itemize}
  \pause
  \vspace{1cm}

  \quad \quad \quad \begin{tabular}{r|c|c|}
    & Single-document & Multi-document\\
    \hline
    Abstractive & \cellcolor{red!25} & \cellcolor{red!25}\\
    \hline
    Extractive & \cellcolor{red!25} & \cellcolor{green!25}\\
    \hline
  \end{tabular}
  %…which hopefully produces coherent, grammatical sentences.
\end{frame}

\begin{frame}
  \frametitle{Linguistic Quality Violations}
  \textbf{Summarization systems \only<2->{\textcolor{red}{don't}}\only<1>{should} produce coherent and grammatical output.}
  \pause

  \textbf{Why?}
  \begin{itemize}
    \item It's hard.\pause
    \item Evaluation: content coverage
  \end{itemize}
  \vspace{1cm}
  \pause
  $\Rightarrow$ LQVSumm \citep{friedrichlqvsumm}

  %doesn't always work. Why?

\end{frame}

\begin{frame}
  \frametitle{LQVSumm \citep{friedrichlqvsumm}}
  %eckdaten, was wurde annotiert
  Annotated automatically created summaries from TAC 2011 Guided Summarization task \citep{owczarzak2011overview}
\pause
  \begin{itemize}
    \item Entity level:
    \begin{itemize}
     % \item first mention without explanation%subsequent mention with explanationFM-EXPL, SM+EXPL%
      \item definite noun phrase without reference to previous mention%DNP-REF, INP+REF%definite noun phrase without reference to previous mention%indefinite noun phrase with reference to previous mention
      \item pronoun with missing antecedent%PRN-ANT, PRN+MISLA%%pronoun with misleading antecedent
      \item acronym without explanations%ACR-EXPL%acronyms without explanations
      \item ...
    \end{itemize}\pause
    \item Clause level:
    \begin{itemize}
      \item \textbf{incomplete sentence (INCOMPLSN)}
      \item \textbf{inclusion of datelines (INCLDATE)}
      \item \textbf{other ungrammatical form (OTHRUNGR)}
      \item no semantic relatedness (NOSEMREL)
      \item \textbf{redundant information (REDUNINF)}
      \item no discourse relation (NODISREL)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{LQVSumm \citep{friedrichlqvsumm}}
  \begin{itemize}
    \item 1935 summaries (TAC part)
    \item few occurences of some types\pause
    \item corpus preprocessing with CoreNLP \citep{manning-EtAl:2014:P14-5}
    \item unit of annotation (clauses vs. sentences)\pause
    \item OTHRUNGR has different violation subtypes (annotated by us)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Development and Test Sets}
  2 development sets:
  \begin{itemize}
    \item \textit{dev-1}: 20\% (D1101-D1108, 351 summaries)
    \item \textit{dev-2}: 20\% (D1109-D1116, 352 summaries)
  \end{itemize}

  \vspace{1cm}
  1 test set: 
  \begin{itemize}
    \item \textit{test}: 60\% (D1117-D1144, 1232 summaries)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Ungrammaticality (OTHRUNGR+INCOMPLSN) on \textit{dev-2}}
  \begin{center}
    \includegraphics[scale=0.4]{subtypes_dev2.png}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Detecting missing spaces}
  \textit{``A strong earthquake measuring 7.8 magnitude struck \textbf{Wenchuancounty} of Sichuan Province on Monday, leaving at least \textbf{12,000people} died and thousands more injured.''}

  \vspace{0.5cm}
  \textit{``Virginia Tech reported a campus shooting Monday and told \textbf{studentsto} stay inside their residences and away from windows.''}

  \vspace{0.5cm}
  \textit{``A gunman opened fire on classrooms at Virginia Tech University \textbf{onMonday} morning, killing at least 30 people before turning his \textbf{gunon} himself in the bloodiest school shooting in US history.''}
\end{frame}

\begin{frame}
  \frametitle{\textbf{UnknownTokens}}
  \textbf{Idea:}

  Sentence contains violation iff any word $\not\in$ known tokens
  \pause
  \vspace{0.6cm}

  \textbf{known tokens?}
  \begin{itemize}
    \item Source documents available? $\rightarrow$ all tokens in source documents = \textbf{UnknownTokens-source}
    \item Otherwise $\rightarrow$ \textbf{UnknownTokens-general}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\textbf{UnknownTokens-general}}
  \begin{itemize}
    \item Tokens from (parts of) Gigaword = \textbf{UnknownTokens-gw}\pause
    \item + Heuristics (Capitalized words) = \textbf{UnknownTokens-gw+heur}\pause
    \item + NER \citep{stanfordNER} = \textbf{UnknownTokens-gw+heur+ner}\pause
    \item + Wikipedia = \textbf{UnknownTokens-gw+heur+ner+wiki}
  \end{itemize}

  = \textbf{UnknownTokens-general}
\end{frame}

\begin{frame}
  \frametitle{\textbf{UnknownTokens}: Evaluation on \textit{dev-2}}
  \begin{tabular}{r|c|c|c|c|c|c|c|c|}
  & \multicolumn{3}{c|}{Missing spaces}\\
  & \textbf{P} & \textbf{R} & \textbf{F}\\
  \hline
  % \textbf{Baseline} & 0.0 & 0.0 & 0.0\\
  % \hline\hline
  \textbf{UT-source} & 95.9 & 94.6 & 95.2\\
  \hline\hline\pause
  \textbf{UT-gw} & 15.0 & \textbf{98.7} & 26.0\\
  \hline\pause
  \textbf{UT-gw+heur} & 30.5 & 97.3 & 46.5\\
  \hline\pause
  \textbf{UT-gw+heur+ner} & 35.5 & 97.3 & 52.0\\
  \hline\pause
  \textbf{UT-gw+heur+ner+wiki} & \textbf{70.3} & 96.0 & \textbf{81.2}\\
  \hline
  \end{tabular}
\end{frame}

\begin{frame}
  \frametitle{Learning  a classifier to detect ungrammatical sentences}
  RandomForest \citep{breiman2001random} to train decision trees
  \vspace{0.6cm}

  \textbf{Features:}\pause
  \begin{itemize}
    \item classification from \textbf{UnknownTokens}\pause
    \item perplexity scores from language model trained on Gigaword\pause
    \item number of words\pause
    \item 3 features from HPSG parser output \citep{ace,copestake2002implementing}:
    \begin{itemize}
      \item number of readings
      \item RAM usage
      \item status
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\textbf{RandomForest}: Evaluation on \textit{test}}
  \quad\quad\textbf{10-fold cross validation:}

  \quad\quad\begin{tabular}{r|c|c|c|c|}
  & \textbf{Precision} & \textbf{Recall} & \textbf{F-Score} & \textbf{Accuracy}\\
  \hline
  \pbox{20cm}{Baseline\\(Most frequent class)} & - & 0 & - & 77.7\\
  \hline
  RandomForest & \textbf{72.8} & 49.1 & \textbf{58.6} & \textbf{84.5}\\
  \hline
  \end{tabular}
  \vspace{0.5cm}\pause

  \quad\quad\textbf{Ablation Study:}

  \vspace{0.25cm}
  \quad\quad\begin{tabular}{c|c}
  \hline\hline
  Feature & Decrease in F-Score\\%84.5391%0.586
  \hline
  UnknownTokens Output & 0.8\\%0.3369\\0.586-0.578
  Language Model Perplexity & 1.4\\%1.2091\\0.586-0.572
  Number of Words & 2.2\\%34\\0.586-0.564
  Parser RAM & 1.3\\%01\\0.586-0.573
  Parser Readings & 5.7\\%478\\0.586-0.529
  Parser Status & 0.4\\%1982\\0.586-0.582
  \hline\hline
  \end{tabular}

\end{frame}

% \begin{frame}%backup with accuracy ablation
%   \frametitle{\textbf{RandomForest}: Evaluation on \textit{test}}
%   10-fold cross validation

%   \quad\quad\begin{tabular}{r|c|c|c|}
%   & \textbf{Precision} & \textbf{Recall} & \textbf{F-Score}\\
%   \hline
%   Ungrammatical & 72.8 & 49.1 & 58.6\\
%   \hline
%   \end{tabular}
%   \vspace{0.5cm}\pause

%   \quad\quad\textbf{Ablation Study:}

%   \vspace{0.25cm}
%   \quad\quad\begin{tabular}{c|c}
%   \hline\hline
%   Feature & Decrease in F-Score\\%84.5391%0.586
%   \hline
%   UnknownTokens Output & 0.34\\%0.3369\\0.586-0.578
%   Language Model Perplexity & 1.21\\%1.2091\\0.586-0.572
%   Number of Words & 0.73\\%34\\0.586-0.564
%   Parser RAM & 1.09\\%01\\0.586-0.573
%   Parser Readings & 1.35\\%478\\0.586-0.529
%   Parser Status & 0.20\\%1982\\0.586-0.582
%   \hline\hline
%   \end{tabular}

% \end{frame}

% \begin{frame}
%   \frametitle{\textbf{RandomForest}: Evaluation}
%   \quad\quad\begin{tabular}{r|c|c|c|}
%   & \textbf{Precision} & \textbf{Recall} & \textbf{F-Score}\\
%   \hline
%   Ungrammatical & 59.6 & 29.3 & 39.3\\
%   \hline\pause
%   Not ungrammatical & 90.1 & 97.0 & 93.4\\
%   \hline
%   Weighted Average & 86.1 & 88.1 & 86.3\\
%   \hline
%   \end{tabular}
% \end{frame}

\begin{frame}
  \frametitle{Datelines (INCLDATE)}
  \textit{\textbf{BLACKSBURG, Virginia 2007-04-16 18:34: 44 UTC} A gunman opened fire in a dorm and classroom at Virginia Tech on Monday, killing at least 30 people in the deadliest shooting rampage in U.S. history.}
  \vspace{0.5cm}

  \textit{\textbf{BERLIN, May 13( Xinhua)} The German government announced on Tuesday that it is to provide 500, 000 euros( around 770, 000 U.S. dollars) in aid for earthquake victims in Sichuan Province of China.}
  \vspace{0.5cm}

  \textit{\textbf{00 a.m.}People are panicking.}
\end{frame}

\begin{frame}
  \frametitle{Detecting Datelines}
  Regular expression:

  \includegraphics[scale=0.4]{regex.png}

  \vspace{1cm}\pause

  \textbf{Evaluation on} \textit{test}:

  \vspace{0.5cm}

  \begin{tabular}{|c|c|c|}
  \hline
  \textbf{Precision} & \textbf{Recall} & \textbf{F-Score}\\
  \hline
  %90.3\% & 91.1 \% & 90.7\%\\
  86.0\% & 89.7\% & 87.8\%\\
  \hline
  \end{tabular}
\end{frame}

\begin{frame}
  \frametitle{Redundancy (REDUNINF)}
  \textit{\textbf{Cyclone} Sidr, described as the worst storm in years to hit low-lying and disaster-prone \textbf{Bangladesh}, crashed into the southwestern coast \textbf{Thursday} night \textbf{before sweeping north} over \textbf{the capital Dhaka.}}
  \vspace{0.1cm}

  \textit{The \textbf{cyclone} hit the southwestern coast of \textbf{Bangladesh} on \textbf{Thursday before sweeping north} to \textbf{the capital Dhaka.}}
\end{frame}

\begin{frame}
  \frametitle{\textbf{Unigrams}}
  \begin{center}
    \only<1>{\textit{Mary saw the 5 ``elephants''. She saw the horses.}}
    \only<2>{$\{Mary, saw, the, 5, elephants\},\{She, saw, the, horses\}$}
    \only<3>{$|\{saw, the\}| = 2$}
    \only<4>{$score = \frac{2}{|\{She, saw, the, horses\}|} = 0.5$}
    \only<5->{$0.5 > threshold$ ?}
  \end{center}\pause

  \begin{itemize}
    \item Remove non-alphanumeric characters and split into set of words\pause
    \item Cardinality of intersection between sets\pause
    \item Normalize by maximum overlap\pause
    \item Classify with threshold\pause
  \end{itemize}

  Variations: \textbf{Bigrams}, \textbf{Combined}

  \vspace{0.5cm}\pause
  Threshold?
\end{frame}

\begin{frame}
  \frametitle{Finding a threshold}
  \center\textit{dev-1+2}

  \quad\includegraphics[scale=0.09]{a.png}
\end{frame}

\begin{frame}
  \frametitle{Evaluation of \textbf{Unigrams}, ... on \textit{test}}
  \begin{tabular}{r|c|c|c|}
    & \textbf{Unigrams} & \textbf{Bigrams} & \textbf{Combined}\\
  \hline
  Threshold & 0.5 & 0.4 & 0.4
  \end{tabular}
  \vspace{1cm}

  \begin{tabular}{r|c|c|c|}
  & Precision & Recall & F-Score \\
  \hline
  \textbf{Baseline} & 4.5\% & \textbf{100\%} & 8.7\% \\
  \hline
  \textbf{Levenshtein} & 15.8\% & 17.3\% & 3.1\% \\
  \hline
  \textbf{Unigrams} & \textbf{58.0\%} & 28.2\% & \textbf{37.0\%} \\
  \hline
  \textbf{Bigrams} & 55.6\% & 14.5\% & 22.9\% \\
  \hline
  \textbf{Combined} & 56.8\% & 24.3\% & 34.0\% \\
  \hline
  \end{tabular}
  \vspace{0.5cm}
\end{frame}

\begin{frame}
  \frametitle{Redundancy: False Negatives}
  \textit{According to a survey by the State \textbf{Food and Drug} Administration, 65 percent of the respondents worried about the food \textbf{safety} situation in China.}
  \vspace{0.1cm}

  \textit{\textbf{Food and drug safety} has become a major concern of Chinese people.}
\end{frame}

\begin{frame}
  \frametitle{Conclusion}
  % \textbf{Methods for:}
  % \begin{itemize}
  %   \item detecting ungrammaticality
  %   \item detecting datelines
  %   \item detecting redundancies
  % \end{itemize}\pause

  \textbf{Best methods:}
  \vspace{0.5cm}

  \begin{tabular}{l|c|c|c|}
  \hline
   & Precision & Recall & F-Score\\
  \hline
  Ungrammaticality & 72.8 & 49.1 & 58.6\\
  \hline
  Datelines & 86.0 & 89.7 & 87.8\\
  \hline
  Redundancy & 58.0 & 28.2 & 37.0\\
  \hline
  \end{tabular}\pause

  \vspace{0.5cm}
  Adapted annotation scheme, better for automatic processing\pause

  \vspace{0.5cm}
  Tool will be made available to annotate with our methods
\end{frame}

\begin{frame}
  \frametitle{Future Work}
  \textbf{Other violations}
  \begin{itemize}
    \item pronouns: coreference resolution
    \item acronyms: finding full form near first unexpanded form
    \item mentions \& noun phrases: NER + ?
    \item no semantic relatedness: semantic parsing? Wordnet distance?
    \item no discourse relation: discourse parsing, does connective match relation?
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Future Work}
  \textbf{Ungrammaticality}
  \begin{itemize}
    \item detection methods for other subtypes
  \end{itemize}\pause
  \vspace{0.5cm}
  \textbf{Redundancy}
  \begin{itemize}
    \item include contextual information
    \item include source document information
    \item semantic approaches
  \end{itemize}\pause
  \vspace{0.5cm}
  \textbf{Corpus}
  \begin{itemize}
    \item annotate a corpus with subtypes, sentence based
    \item evaluate methods on other data sets/corpora/domains
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{References}
  \bibliographystyle{apalike}
  \footnotesize\bibliography{referenzen}
\end{frame}

%----------------------------------------------------------------------------------------------------------------
\begin{frame}
  \frametitle{Bonus Slide: Full \textbf{UnknownTokens} Evaluation}
  \begin{tabular}{r|c|c|c|c|c|c|c|c|}
  & \multicolumn{3}{c|}{Missing spaces} & \multicolumn{3}{c|}{No missing spaces}\\
  & \textbf{P} & \textbf{R} & \textbf{F} & \textbf{P} & \textbf{R} & \textbf{F}\\
  \hline
  \textbf{Baseline} & 0.0 & 0.0 & 0.0 & 94.8 & \textbf{100} & 97.3\\
  \hline\hline
  \textbf{UT\textsubscript{gw}} & 15.0 & \textbf{98.7} & 26.0 & \textbf{99.9} & 69.1 & 81.7\\
  \hline
  \textbf{UT\textsubscript{gw+heur}} & 30.5 & 97.3 & 46.5 & 99.8 & 87.8 & 93.4\\
  \hline
  \textbf{UT\textsubscript{gw+heur+ner}} & 35.5 & 97.3 & 52.0 & 99.8 & 90.3 & 94.8\\
  \hline
  \textbf{UT\textsubscript{gw+heur+ner+wiki}} & 70.3 & 96.0 & 81.2 & 99.8 & 97.8 & 98.8\\
  \hline\hline
  \textbf{UT\textsubscript{source}} & \textbf{95.9} & 94.6 & \textbf{95.2} & 99.7 & 99.7 & \textbf{99.7}\\
  \hline
  \end{tabular}
\end{frame}

\begin{frame}
  \frametitle{Bonus Slide: \textbf{RandomForest}: Evaluation of all classes}
  \quad\quad\begin{tabular}{r|c|c|c|}
  & \textbf{Precision} & \textbf{Recall} & \textbf{F-Score}\\
  \hline
  Ungrammatical & 72.8 & 49.1 & 58.6\\
  \hline\pause
  Not ungrammatical & 86.6 & 94.7 & 90.5\\
  \hline
  Weighted Average & 83.5 & 84.5 & 83.4\\
  \hline
  \end{tabular}
\end{frame}

% \begin{frame}
%   \quad\quad\includegraphics[scale=0.6]{thesis_defense.png}
% \end{frame}

\end{document}